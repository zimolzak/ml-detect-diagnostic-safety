{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dizzy_util as util\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_CATALOG</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_cohort</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_30_Note_WithRole</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_30_Note</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_04_04_Lab</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_05_BCMA_Dispense...</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_08_AllMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_08_Consult</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_12_ICD</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_14_Vital</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_16_HF</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad_new</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_Demorgraphics</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TABLE_CATALOG TABLE_SCHEMA  \\\n",
       "0   ORD_Singh_201911038D         Dflt   \n",
       "1   ORD_Singh_201911038D         Dflt   \n",
       "2   ORD_Singh_201911038D         Dflt   \n",
       "3   ORD_Singh_201911038D         Dflt   \n",
       "4   ORD_Singh_201911038D         Dflt   \n",
       "5   ORD_Singh_201911038D         Dflt   \n",
       "6   ORD_Singh_201911038D         Dflt   \n",
       "7   ORD_Singh_201911038D         Dflt   \n",
       "8   ORD_Singh_201911038D         Dflt   \n",
       "9   ORD_Singh_201911038D         Dflt   \n",
       "10  ORD_Singh_201911038D         Dflt   \n",
       "11  ORD_Singh_201911038D         Dflt   \n",
       "12  ORD_Singh_201911038D         Dflt   \n",
       "13  ORD_Singh_201911038D         Dflt   \n",
       "14  ORD_Singh_201911038D         Dflt   \n",
       "\n",
       "                                           TABLE_NAME  TABLE_TYPE  \n",
       "0                 _B00_ML4TrgPos_Y201621_01_04_cohort  BASE TABLE  \n",
       "1                    _B00_ML4TrgPos_Y201621_05_04_Rad  BASE TABLE  \n",
       "2             _B00_ML4TrgPos_Y201621_30_Note_WithRole  BASE TABLE  \n",
       "3                      _B00_ML4TrgPos_Y201621_30_Note  BASE TABLE  \n",
       "4                    _B00_ML4TrgPos_Y201621_04_04_Lab  BASE TABLE  \n",
       "5           _B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat  BASE TABLE  \n",
       "6           _B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed  BASE TABLE  \n",
       "7   _B00_ML4TrgPos_Y201621_06_Med_05_BCMA_Dispense...  BASE TABLE  \n",
       "8             _B00_ML4TrgPos_Y201621_06_Med_08_AllMed  BASE TABLE  \n",
       "9                   _B00_ML4TrgPos_Y201621_08_Consult  BASE TABLE  \n",
       "10                      _B00_ML4TrgPos_Y201621_12_ICD  BASE TABLE  \n",
       "11                    _B00_ML4TrgPos_Y201621_14_Vital  BASE TABLE  \n",
       "12                       _B00_ML4TrgPos_Y201621_16_HF  BASE TABLE  \n",
       "13               _B00_ML4TrgPos_Y201621_05_04_Rad_new  BASE TABLE  \n",
       "14         _B00_ML4TrgPos_Y201621_01_04_Demorgraphics  BASE TABLE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cohort', 'Rad', 'Note', 'Lab', 'RxOutpat', 'NonVAMed', 'Consult', 'ICD', 'new', 'Demorgraphics'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = util.extractDataset(\"B00_ML4TrgPos_\", {\"WithRole\", \"AllMed\", \"Vital\", \"HF\", \"DispensedDrug\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df, label_map = util.retrieveLabels() # labeled\n",
    "label_df = util.convertLabelMap(label_map) # PatientSSN | Label (100)\n",
    "datasubset = util.extractAndStandarizeCohort(dataset, \"Dizziness\") # dataset for dizziness (All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasubset[\"cohort\"] = datasubset[\"cohort\"].merge(label_df.rename(columns={\"PatientSSN\":\"patientSSN\"})) # concat label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubset(ds, subsetNames):\n",
    "    pkeys = util.getPrimaryKeys(dataset)\n",
    "    cohort_key = pkeys[\"cohort\"]\n",
    "    cohort_subset = ds[\"cohort\"][ds[\"cohort\"].Label.isin(subsetNames)]\n",
    "    ids = pd.DataFrame({cohort_key: cohort_subset[cohort_key].unique()})\n",
    "    dss = dict()\n",
    "    for table, df in ds.items():\n",
    "        dss[table] = ids.merge(df, how=\"inner\", left_on=cohort_key, right_on=pkeys[table])\n",
    "        if pkeys[table] != cohort_key:\n",
    "            dss[table] = dss[table].drop([cohort_key], axis = 1)\n",
    "        dss[table][pkeys[table]] = dss[table][pkeys[table]].astype(int)\n",
    "    return dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsubset = extractSubset(datasubset, [\"MOD\"]) # dizziness MOD cases\n",
    "nomodsubset = extractSubset(datasubset, [\"NoMOD\"]) # dizziness no-MOD cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientSSN', 'EntryDateTime', 'TIUDocumentSID', 'TIUStandardTitle',\n",
      "       'ReportText', 'Sta3n', 'PatientSID', 'ProviderRole'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(modsubset['Note'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEDorPhysician(df):\n",
    "    pattern = 'EMERGENCY DEPT NOTE|PHYSICIAN NOTE'\n",
    "    return df[df.TIUStandardTitle.str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ed_or_physician_df = getEDorPhysician(modsubset['Note'])\n",
    "nomod_ed_or_physician_df = getEDorPhysician(nomodsubset['Note'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMERGENCY DEPT NOTE' 'PHYSICAL MEDICINE REHAB PHYSICIAN NOTE'\n",
      " 'NURSING EMERGENCY DEPT NOTE' 'PHYSICIAN NOTE'\n",
      " 'PHYSICIAN EMERGENCY DEPT NOTE' 'SOCIAL WORK EMERGENCY DEPT NOTE'\n",
      " 'PRIMARY CARE PHYSICIAN NOTE' 'INTERNAL MEDICINE PHYSICIAN NOTE'\n",
      " 'PHYSICAL THERAPY PHYSICIAN NOTE' 'PALLIATIVE CARE PHYSICIAN NOTE'\n",
      " 'SCANNED EMERGENCY DEPT NOTE' 'PULMONARY PHYSICIAN NOTE'\n",
      " 'MENTAL HEALTH PHYSICIAN NOTE' 'ATTENDING EMERGENCY DEPT NOTE'\n",
      " 'NEUROLOGY PHYSICIAN NOTE' 'ANESTHESIOLOGY PHYSICIAN NOTE'\n",
      " 'DERMATOLOGY PHYSICIAN NOTE' 'DIALYSIS PHYSICIAN NOTE'\n",
      " 'UROLOGY PHYSICIAN NOTE']\n"
     ]
    }
   ],
   "source": [
    "print(mod_ed_or_physician_df['TIUStandardTitle'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getLastEntryOfNote(df):\n",
    "    idnote_to_note = defaultdict(str)\n",
    "    for index, row in df.iterrows():\n",
    "        idnote_to_note[(row['PatientSSN'], row['TIUStandardTitle'])] = row['ReportText']\n",
    "    return idnote_to_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mod_dict = getLastEntryOfNote(mod_ed_or_physician_df)\n",
    "filtered_nomod_dict = getLastEntryOfNote(nomod_ed_or_physician_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mod_df = pd.DataFrame(filtered_mod_dict.values(), columns =[\"ReportText\"])\n",
    "filtered_nomod_df = pd.DataFrame(filtered_nomod_dict.values(), columns =[\"ReportText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts = filtered_mod_df.reset_index(drop=True)\n",
    "nomod_texts = filtered_nomod_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing(text):\n",
    "    y = ''\n",
    "    if text:\n",
    "        y = text.lower()\n",
    "        y = re.sub(r'\\\\[(.*?)\\\\]', '', y)\n",
    "        y = re.sub(r'[0-9]+\\.', '', y)\n",
    "        y = re.sub(r'dr\\.', 'doctor', y)\n",
    "        y = re.sub(r'm\\.d\\.', 'md', y)\n",
    "        y = re.sub(r'--|__|==', '', y) \n",
    "        y = re.sub(r'y\\.o\\.', 'year old', y)\n",
    "        y = re.sub(r'fh', 'family history', y)\n",
    "        y = re.sub(r'sh:', 'social history:', y)\n",
    "        y = re.sub(r'\\r\\n', ' ', y)\n",
    "        y = re.sub(r' :', ':', y)\n",
    "        y = re.sub(r'physical examination', 'physical exam', y)\n",
    "        y = re.sub(r'medications/iv:', 'medications:', y)\n",
    "        ######### prevent catching as section\n",
    "        y = re.sub(r'consult', 'consultation', y)\n",
    "        y = re.sub(r'allergies', 'allergy', y) # allergies: stay the same but allergie -> allergy\n",
    "        y = re.sub(r'allergy:', 'allergies:', y)\n",
    "        y = re.sub(r'past history', 'past histories', y) # past history: stay the same but history -> histories, not ran for mod.\n",
    "        y = re.sub(r'past histories:', 'past history:', y) # not ran for mods.\n",
    "        y = re.sub(r'/ ', '/', y)\n",
    "        y = re.sub(r'plan/disposition', 'plan', y)\n",
    "        y = re.sub(r'=', '', y)\n",
    "        ####### 11/5 added\n",
    "        y = re.sub(r'\\[\\]', 'not ', y)\n",
    "        y = re.sub(r'\\[x\\]', '', y)\n",
    "        y = re.sub(r':', ': ', y)\n",
    "        y = re.sub(r'\\.', '. ', y)\n",
    "        y = re.sub(r'assessment \\& plan:', 'assessment:', y)\n",
    "        y = re.sub(r'vitals:', 'vital signs', y)\n",
    "        y = re.sub(r'active and recently expired inpatient medications \\(including supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'active outpatient medications \\(including supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'active inpatient medications \\(including supplies\\):', 'medications:',  y)\n",
    "        y = re.sub(r'active outpatient medications \\(excluding supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'reason for visit \\(chief complaint\\):', 'cc:', y)\n",
    "        y = re.sub(r'lab results:', 'labs:', y)\n",
    "        # very specific ones\n",
    "        y = re.sub(r'med reconciliation  included in this list:', 'medications:', y)\n",
    "        y = re.sub(r'51 y/o wm who', 'hpi: 51 y/o wm who', y)\n",
    "        y = re.sub(r'reason for visit \\(cc\\):', 'cc:', y)\n",
    "        y = re.sub(r'gen:', 'general:', y)\n",
    "        y = re.sub(r'68 year old male appears', 'general: 68 year old male appears', y)\n",
    "        y = re.sub(r'cc-', 'cc:', y)\n",
    "        y = re.sub(r'hpi-', 'hpi:', y)\n",
    "        y = re.sub('  +', ' ', y)  # whitespace\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "mod_texts['ReportText'] = mod_texts['ReportText'].map(preprocessing)\n",
    "mod_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomod_texts['ReportText'] = nomod_texts['ReportText'].map(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "from medspacy.visualization import visualize_ent, visualize_dep\n",
    "from medspacy.custom_tokenizer import create_medspacy_tokenizer\n",
    "from medspacy.section_detection import Sectionizer\n",
    "from medspacy.section_detection import SectionRule\n",
    "#from quickumls import QuickUMLS\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(\"en_core_sci_sm\")\n",
    "nlp.disable_pipe('parser')\n",
    "nlp.disable_pipe('medspacy_target_matcher') # matcher: disable warning, ok doesn't help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_context',\n",
       " 'medspacy_sectionizer']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectionizer = nlp.add_pipe(\"medspacy_sectionizer\", config={\"rules\": \"default\"})\n",
    "section_patterns = [\n",
    "    SectionRule(category=\"history\",literal=\"past medical/surgical history:\"),\n",
    "    SectionRule(category=\"history\",literal=\"medical history:\"),\n",
    "    SectionRule(category=\"history\",literal=\"surgical history:\"),\n",
    "    # added\n",
    "    SectionRule(category=\"history\",literal=\"cvabackground:\"),\n",
    "    SectionRule(category=\"status\",literal=\"patient care status:\"),\n",
    "    SectionRule(category=\"other\",literal=\"other:\"),\n",
    "    SectionRule(category=\"treatment\",literal=\"treatments/therapies:\"),\n",
    "    SectionRule(category=\"preview\",literal=\"subjectives:\"),\n",
    "    SectionRule(category=\"diagnosis\",literal=\"diagnosis:\",pattern=[{\"LOWER\": {\"REGEX\": \".*admi(tting|ssion)\"}}, {\"LOWER\": \"diagnosis\"}, {\"LOWER\": \":\"}]),\n",
    "    SectionRule(category=\"review\",literal=\"review of system:\"),\n",
    "    SectionRule(category=\"diagnosis\",literal=\"assessment/diagnosis:\"),\n",
    "    SectionRule(category=\"status\",literal=\"general:\"),\n",
    "    SectionRule(category=\"followup\",literal=\"discussed with pt:\"),\n",
    "    \n",
    "]\n",
    "sectionizer.add(section_patterns)\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSection(text):\n",
    "    filteredtext = \"\"\n",
    "    current_doc = nlp(text)  \n",
    "    for title, body in zip(current_doc._.section_titles, current_doc._.section_bodies):\n",
    "        if title.text != 'medications:':\n",
    "            filteredtext += body.text\n",
    "            filteredtext += \" \"\n",
    "    return filteredtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts['ReportText'] = mod_texts['ReportText'].map(getSection)\n",
    "nomod_texts['ReportText'] = nomod_texts['ReportText'].map(getSection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_texts['ReportText'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 grams & 3 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(words, ngram_size, output_dict):\n",
    "    for i in range(len(words) - ngram_size + 1):\n",
    "        output_dict[' '.join(words[i:i+ngram_size])] += 1\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "mod_2gram = collections.Counter()\n",
    "mod_3gram = collections.Counter()\n",
    "\n",
    "for note in mod_texts['ReportText']:\n",
    "    words = note.split(' ')\n",
    "    words = filter(lambda x: x != '', words)\n",
    "    words = list(words)\n",
    "    print(words)\n",
    "    mod_2gram = generate_ngrams(words, 2, mod_2gram)\n",
    "    mod_3gram = generate_ngrams(words, 3, mod_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort frequency of occurrence\n",
    "pd.set_option('display.max_rows', 300)\n",
    "mod_bigrams_df = pd.DataFrame.from_dict(mod_2gram, orient='index').reset_index()\n",
    "mod_bigrams_df.columns = ['word','count']\n",
    "mod_bigrams_df.sort_values(by='count',ascending=False)[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod_trigrams_df = pd.DataFrame.from_dict(mod_3gram,orient='index').reset_index()\n",
    "mod_trigrams_df.columns = ['word','count']\n",
    "mod_trigrams_df.sort_values(by='count',ascending=False)[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomod_2gram = collections.Counter()\n",
    "nomod_3gram = collections.Counter()\n",
    "\n",
    "for note in nomod_texts['ReportText']:\n",
    "    words = preprocessing(note).split(' ')\n",
    "    words = filter(lambda x: x != '', words)\n",
    "    words = list(words)\n",
    "    nomod_2gram = generate_ngrams(words, 2, nomod_2gram)\n",
    "    nomod_3gram = generate_ngrams(words, 3, nomod_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomod_bigrams_df = pd.DataFrame.from_dict(nomod_2gram, orient='index').reset_index()\n",
    "nomod_bigrams_df.columns = ['word','count']\n",
    "nomod_bigrams_df.sort_values(by='count',ascending=False)[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomod_trigrams_df = pd.DataFrame.from_dict(nomod_3gram,orient='index').reset_index()\n",
    "nomod_trigrams_df.columns = ['word','count']\n",
    "nomod_trigrams_df.sort_values(by='count',ascending=False)[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'a', 'cat.']\n"
     ]
    }
   ],
   "source": [
    "text = 'I am a  cat.'\n",
    "asd = text.split(' ')\n",
    "asd = filter(lambda x: x != '', asd)\n",
    "print(list(asd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
