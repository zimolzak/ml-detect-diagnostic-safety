{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract needed data - Physician or ED notes, last entry per (person, note type) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dizzy_util as util\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_CATALOG</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_cohort</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_30_Note_WithRole</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_30_Note</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_04_04_Lab</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_08_AllMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_08_Consult</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_12_ICD</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_14_Vital</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_16_HF</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad_new</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_Demorgraphics</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TABLE_CATALOG TABLE_SCHEMA  \\\n",
       "0   ORD_Singh_201911038D         Dflt   \n",
       "1   ORD_Singh_201911038D         Dflt   \n",
       "2   ORD_Singh_201911038D         Dflt   \n",
       "3   ORD_Singh_201911038D         Dflt   \n",
       "4   ORD_Singh_201911038D         Dflt   \n",
       "5   ORD_Singh_201911038D         Dflt   \n",
       "6   ORD_Singh_201911038D         Dflt   \n",
       "7   ORD_Singh_201911038D         Dflt   \n",
       "8   ORD_Singh_201911038D         Dflt   \n",
       "9   ORD_Singh_201911038D         Dflt   \n",
       "10  ORD_Singh_201911038D         Dflt   \n",
       "11  ORD_Singh_201911038D         Dflt   \n",
       "12  ORD_Singh_201911038D         Dflt   \n",
       "13  ORD_Singh_201911038D         Dflt   \n",
       "14  ORD_Singh_201911038D         Dflt   \n",
       "15  ORD_Singh_201911038D         Dflt   \n",
       "\n",
       "                                                     TABLE_NAME  TABLE_TYPE  \n",
       "0                           _B00_ML4TrgPos_Y201621_01_04_cohort  BASE TABLE  \n",
       "1                              _B00_ML4TrgPos_Y201621_05_04_Rad  BASE TABLE  \n",
       "2                       _B00_ML4TrgPos_Y201621_30_Note_WithRole  BASE TABLE  \n",
       "3                                _B00_ML4TrgPos_Y201621_30_Note  BASE TABLE  \n",
       "4                              _B00_ML4TrgPos_Y201621_04_04_Lab  BASE TABLE  \n",
       "5                     _B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat  BASE TABLE  \n",
       "6                     _B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed  BASE TABLE  \n",
       "7           _B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug  BASE TABLE  \n",
       "8                       _B00_ML4TrgPos_Y201621_06_Med_08_AllMed  BASE TABLE  \n",
       "9                             _B00_ML4TrgPos_Y201621_08_Consult  BASE TABLE  \n",
       "10                                _B00_ML4TrgPos_Y201621_12_ICD  BASE TABLE  \n",
       "11                              _B00_ML4TrgPos_Y201621_14_Vital  BASE TABLE  \n",
       "12                                 _B00_ML4TrgPos_Y201621_16_HF  BASE TABLE  \n",
       "13                         _B00_ML4TrgPos_Y201621_05_04_Rad_new  BASE TABLE  \n",
       "14                   _B00_ML4TrgPos_Y201621_01_04_Demorgraphics  BASE TABLE  \n",
       "15  _B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter  BASE TABLE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\VHAHOUWuY1\\AppData\\Local\\Continuum\\anaconda3\\envs\\ahrq-sci-med\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cohort', 'Note'])\n"
     ]
    }
   ],
   "source": [
    "dataset = util.extractDataset(\"B00_ML4TrgPos_\", {\"WithRole\", \"AllMed\", \"Vital\", \"HF\", \"DispensedDrug\",'Rad', 'Lab', 'RxOutpat', 'NonVAMed', 'Consult', 'ICD', 'new', 'Demorgraphics', 'Only10daysPrior30DaysAfter' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df, label_map = util.retrieveLabels() # labeled\n",
    "label_df = util.convertLabelMap(label_map) # PatientSSN | Label (100)\n",
    "datasubset = util.extractAndStandarizeCohort(dataset, \"Dizziness\") # dataset for dizziness (All).\n",
    "edstart = util.extractFirstVisitIndexDatetime(datasubset[\"cohort\"]) # get first entry of each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoMOD       44\n",
       "MOD         38\n",
       "PMOD        12\n",
       "CodingEr     6\n",
       "Name: DxErrorERCoded, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizziness_df[\"DxErrorERCoded\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasubset[\"cohort\"] = datasubset[\"cohort\"].merge(label_df.rename(columns={\"PatientSSN\":\"patientSSN\"})) # concat label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubset(ds, subsetNames):\n",
    "    pkeys = util.getPrimaryKeys(dataset)\n",
    "    cohort_key = pkeys[\"cohort\"]\n",
    "    cohort_subset = ds[\"cohort\"][ds[\"cohort\"].Label.isin(subsetNames)]\n",
    "    ids = pd.DataFrame({cohort_key: cohort_subset[cohort_key].unique()})\n",
    "    dss = dict()\n",
    "    for table, df in ds.items():\n",
    "        dss[table] = ids.merge(df, how=\"inner\", left_on=cohort_key, right_on=pkeys[table])\n",
    "        if pkeys[table] != cohort_key:\n",
    "            dss[table] = dss[table].drop([cohort_key], axis = 1)\n",
    "        dss[table][pkeys[table]] = dss[table][pkeys[table]].astype(int)\n",
    "    return dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsubset = extractSubset(datasubset, [\"MOD\"]) # dizziness MOD cases\n",
    "nomodsubset = extractSubset(datasubset, [\"NoMOD\"]) # dizziness no-MOD cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientSSN', 'EntryDateTime', 'TIUDocumentSID', 'TIUStandardTitle',\n",
      "       'ReportText', 'Sta3n', 'PatientSID', 'ProviderRole'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(modsubset['Note'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEDorPhysician(df):\n",
    "    pattern = 'EMERGENCY DEPT NOTE|PHYSICIAN NOTE'\n",
    "    return df[df.TIUStandardTitle.str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ed_or_physician_df = getEDorPhysician(modsubset['Note']).sort_values(\"EntryDateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomod_ed_or_physician_df = getEDorPhysician(nomodsubset['Note']).sort_values(\"EntryDateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NURSING EMERGENCY DEPT NOTE' 'EMERGENCY DEPT NOTE'\n",
      " 'PRIMARY CARE PHYSICIAN NOTE' 'PHYSICAL MEDICINE REHAB PHYSICIAN NOTE'\n",
      " 'ATTENDING EMERGENCY DEPT NOTE' 'MENTAL HEALTH PHYSICIAN NOTE'\n",
      " 'PHYSICIAN NOTE' 'NEUROLOGY PHYSICIAN NOTE'\n",
      " 'PHYSICIAN EMERGENCY DEPT NOTE' 'UROLOGY PHYSICIAN NOTE'\n",
      " 'SCANNED EMERGENCY DEPT NOTE' 'PULMONARY PHYSICIAN NOTE'\n",
      " 'PHYSICAL THERAPY PHYSICIAN NOTE' 'ANESTHESIOLOGY PHYSICIAN NOTE'\n",
      " 'DERMATOLOGY PHYSICIAN NOTE' 'PALLIATIVE CARE PHYSICIAN NOTE'\n",
      " 'SOCIAL WORK EMERGENCY DEPT NOTE' 'DIALYSIS PHYSICIAN NOTE'\n",
      " 'INTERNAL MEDICINE PHYSICIAN NOTE']\n"
     ]
    }
   ],
   "source": [
    "print(mod_ed_or_physician_df['TIUStandardTitle'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getLastEntryOfNote(df):\n",
    "    idnote_to_note = defaultdict(str)\n",
    "    for index, row in df.iterrows():\n",
    "        idnote_to_note[(row['PatientSSN'], row['TIUStandardTitle'])] = [row['PatientSSN'], row['TIUStandardTitle'], row['ReportText']]\n",
    "    return idnote_to_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mod_dict = getLastEntryOfNote(mod_ed_or_physician_df) \n",
    "filtered_nomod_dict = getLastEntryOfNote(nomod_ed_or_physician_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mod_df = pd.DataFrame(filtered_mod_dict.values(), columns =[\"PatientSSN\", \"TIUStandardTitle\",\"ReportText\"])\n",
    "filtered_nomod_df = pd.DataFrame(filtered_nomod_dict.values(), columns =[\"PatientSSN\", \"TIUStandardTitle\",\"ReportText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatePersonNotes(df):\n",
    "    person_to_notes = defaultdict(str)\n",
    "    for index, row in df.iterrows():\n",
    "        person_to_notes[row['PatientSSN']] += row['ReportText']\n",
    "        person_to_notes[row['PatientSSN']] += \" \"\n",
    "    return person_to_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_all_text_dict = concatePersonNotes(filtered_mod_df) \n",
    "nomod_all_text_dict = concatePersonNotes(filtered_nomod_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 40\n"
     ]
    }
   ],
   "source": [
    "print(len(mod_all_text_dict), len(nomod_all_text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mod_ssn_df = pd.DataFrame(mod_all_text_dict.keys(), columns =[\"PatientSSN\"])\n",
    "filtered_mod_txt_df = pd.DataFrame(mod_all_text_dict.values(), columns =[\"ReportText\"])\n",
    "filtered_mod_df = pd.concat((filtered_mod_ssn_df, filtered_mod_txt_df), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_nomod_ssn_df = pd.DataFrame(nomod_all_text_dict.keys(), columns =[\"PatientSSN\"])\n",
    "filtered_nomod_txt_df = pd.DataFrame(nomod_all_text_dict.values(), columns =[\"ReportText\"])\n",
    "filtered_nomod_df = pd.concat((filtered_nomod_ssn_df, filtered_nomod_txt_df), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts = filtered_mod_df.reset_index(drop=True)\n",
    "nomod_texts = filtered_nomod_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing(text):\n",
    "    y = ''\n",
    "    if text:\n",
    "        y = text.lower()\n",
    "        y = re.sub(r'\\\\[(.*?)\\\\]', '', y)\n",
    "        y = re.sub(r'[0-9]+\\.', '', y)\n",
    "        y = re.sub(r'dr\\.', 'doctor', y)\n",
    "        y = re.sub(r'm\\.d\\.', 'md', y)\n",
    "        y = re.sub(r'--|__|==', '', y) \n",
    "        y = re.sub(r'y\\.o\\.', 'year old', y)\n",
    "        y = re.sub(r'fh', 'family history', y)\n",
    "        y = re.sub(r'sh:', 'social history:', y)\n",
    "        y = re.sub(r'\\r\\n', ' ', y)\n",
    "        y = re.sub(r' :', ':', y)\n",
    "        y = re.sub(r'physical examination', 'physical exam', y)\n",
    "        y = re.sub(r'medications/iv:', 'medications:', y)\n",
    "        ######### prevent catching as section\n",
    "        y = re.sub(r'consult', 'consultation', y)\n",
    "        y = re.sub(r'allergies', 'allergy', y) # allergies: stay the same but allergie -> allergy\n",
    "        y = re.sub(r'allergy:', 'allergies:', y)\n",
    "        y = re.sub(r'past history', 'past histories', y) # past history: stay the same but history -> histories, not ran for mod.\n",
    "        y = re.sub(r'past histories:', 'past history:', y)\n",
    "        y = re.sub(r'/ ', '/', y)\n",
    "        y = re.sub(r'plan/disposition', 'plan', y)\n",
    "        y = re.sub(r'=', '', y)\n",
    "        y = re.sub(r'\\[\\]', 'not ', y)\n",
    "        y = re.sub(r'\\[x\\]', '', y)\n",
    "        y = re.sub(r':', ': ', y)\n",
    "        y = re.sub(r'\\.', '. ', y)\n",
    "        y = re.sub(r'assessment \\& plan:', 'assessment:', y)\n",
    "        y = re.sub(r'vitals:', 'vital signs', y)\n",
    "        y = re.sub(r'active and recently expired inpatient medications \\(including supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'active outpatient medications \\(including supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'active inpatient medications \\(including supplies\\):', 'medications:',  y)\n",
    "        y = re.sub(r'active outpatient medications \\(excluding supplies\\):', 'medications:', y)\n",
    "        y = re.sub(r'reason for visit \\(chief complaint\\):', 'cc:', y)\n",
    "        y = re.sub(r'lab results:', 'labs:', y)\n",
    "        y = re.sub(r'med reconciliation  included in this list:', 'medications:', y)\n",
    "        y = re.sub(r'reason for visit \\(cc\\):', 'cc:', y)\n",
    "        y = re.sub(r'gen:', 'general:', y)\n",
    "        y = re.sub(r'cc-', 'cc:', y)\n",
    "        y = re.sub(r'hpi-', 'hpi:', y)\n",
    "        y = re.sub('  +', ' ', y)  # whitespace\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "mod_texts['ReportText'] = mod_texts['ReportText'].map(preprocessing)\n",
    "nomod_texts['ReportText'] = nomod_texts['ReportText'].map(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build Bag Of Cuis Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "from medspacy.visualization import visualize_ent, visualize_dep\n",
    "from medspacy.custom_tokenizer import create_medspacy_tokenizer\n",
    "from medspacy.section_detection import Sectionizer\n",
    "from medspacy.section_detection import SectionRule\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(\"en_core_sci_sm\")\n",
    "nlp.disable_pipe('parser')\n",
    "nlp.disable_pipe('medspacy_target_matcher') # matcher: disable warning, doesn't help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_context',\n",
       " 'medspacy_sectionizer']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectionizer = nlp.add_pipe(\"medspacy_sectionizer\", config={\"rules\": \"default\"})\n",
    "section_patterns = [\n",
    "    SectionRule(category=\"history\",literal=\"past medical/surgical history:\"),\n",
    "    SectionRule(category=\"history\",literal=\"medical history:\"),\n",
    "    SectionRule(category=\"history\",literal=\"surgical history:\"),\n",
    "    # added\n",
    "    SectionRule(category=\"history\",literal=\"cvabackground:\"),\n",
    "    SectionRule(category=\"status\",literal=\"patient care status:\"),\n",
    "    SectionRule(category=\"other\",literal=\"other:\"),\n",
    "    SectionRule(category=\"treatment\",literal=\"treatments/therapies:\"),\n",
    "    SectionRule(category=\"preview\",literal=\"subjectives:\"),\n",
    "    SectionRule(category=\"diagnosis\",literal=\"diagnosis:\",pattern=[{\"LOWER\": {\"REGEX\": \".*admi(tting|ssion)\"}}, {\"LOWER\": \"diagnosis\"}, {\"LOWER\": \":\"}]),\n",
    "    SectionRule(category=\"review\",literal=\"review of system:\"),\n",
    "    SectionRule(category=\"diagnosis\",literal=\"assessment/diagnosis:\"),\n",
    "    SectionRule(category=\"status\",literal=\"general:\"),\n",
    "    SectionRule(category=\"followup\",literal=\"discussed with pt:\"),\n",
    "    \n",
    "]\n",
    "sectionizer.add(section_patterns)\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Sections Other than Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoidsections = ['medications:', 'active medications:', 'current medications:', 'discharge medications:', 'other:', 'education:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSection(text):\n",
    "    filteredtext = \"\"\n",
    "    current_doc = nlp(text)  \n",
    "    for title, body in zip(current_doc._.section_titles, current_doc._.section_bodies):\n",
    "        if title.text not in avoidsections: # filter out medication.\n",
    "            filteredtext += body.text\n",
    "            filteredtext += \" \"\n",
    "    return filteredtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts['ReportText'] = mod_texts['ReportText'].map(getSection)\n",
    "nomod_texts['ReportText'] = nomod_texts['ReportText'].map(getSection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "mod_texts, test_mod_texts = train_test_split(mod_texts, test_size = 0.2)\n",
    "nomod_texts, test_nomod_texts = train_test_split(nomod_texts, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts = mod_texts.reset_index(drop=True)\n",
    "nomod_texts = nomod_texts.reset_index(drop=True)\n",
    "test_mod_texts = test_mod_texts.reset_index(drop=True)\n",
    "test_nomod_texts = test_nomod_texts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(test_mod_texts), len(test_nomod_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 32\n"
     ]
    }
   ],
   "source": [
    "print(len(mod_texts), len(nomod_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tfidf for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllCuisAndCuiDict(df, allCuis):\n",
    "    noteToCuis = defaultdict(list)    \n",
    "    for index, row in df.iterrows():\n",
    "        current_doc = nlp(row['ReportText'])        \n",
    "        for entity in current_doc.ents:\n",
    "            noteToCuis[index] += [entity.lemma_]\n",
    "            allCuis[entity.lemma_] += 1\n",
    "    return allCuis, noteToCuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "allCuis = collections.Counter()\n",
    "allCuis, mod_note_to_cuis = getAllCuisAndCuiDict(mod_texts, allCuis)\n",
    "allCuis, nomod_note_to_cuis = getAllCuisAndCuiDict(nomod_texts, allCuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'day', 'tablet', 'tab', 'mouth', '/', 'medication', 'refill', 'supply', 'pain', 'report', 'expiration', 'release', 'eval', 'negative', '|', 'review', 'intact', 'pulse', 'specimen', 'qty', 'male', 'skin', 'plan', 'deny', 'symptom', 'time', 'outpt', 'test', 'stable', 'week', 'month', 'blood', 'provider', 'year', 'soft', 'blood pressure', 'collection', 'p', 'lab', 'level', 'alert', 'bilaterally', 'veteran', 'daily', 'date', 'hyperlipidemia', 'hypertension', 'answer', 'active', 'discharge', 'history', 'treatment', 'risk', 'status active', 'mild', 'mmol', 'status discontinue', 'eye', 'egfr', 'admission', 'change', 'dose', 'abdoman', 'hour', 'pcp', 'lesion', 'problem', 'unit', 'dizziness', 'bilateral', 'calcium', 'comment', 'htn', 'neck', 'fever', 'result', 'stroke', 'state', 'sob', 'site', 'serum', 'caregiver', 'nurse', 'head', 'lung', 'moderate', 'give', 'pulse oximetry', 'admit', 'atrial fibrillation', 'aneurysm', 'smoke', 'head trauma']\n"
     ]
    }
   ],
   "source": [
    "allCuisListCount = allCuis.most_common(90)\n",
    "allCuisList = [word for word, count in allCuisListCount]\n",
    "# add risk factors\n",
    "allCuisList += ['atrial fibrillation']\n",
    "allCuisList += ['aneurysm']\n",
    "allCuisList += ['smoke']\n",
    "allCuisList += ['head trauma']\n",
    "print(allCuisList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Cui to index dictionary.\n",
    "cuiToIndex = {}\n",
    "for index, cui in enumerate(allCuisList):\n",
    "    cuiToIndex[cui] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bagOfCuisCount = np.zeros((len(mod_texts)+len(nomod_texts), len(allCuisList)))\n",
    "bagOfCuisExist = np.zeros((len(mod_texts)+len(nomod_texts), len(allCuisList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populateWordCountAndExistence(bagOfCuisCount, bagOfCuisExist, noteToCuis, shifter=0):\n",
    "    for noteIndex, cuiList in noteToCuis.items():\n",
    "        for cui in cuiList:\n",
    "            if cui in cuiToIndex: # make sure it's in top k.\n",
    "                bagOfCuisCount[noteIndex + shifter][cuiToIndex[cui]] += 1\n",
    "                bagOfCuisExist[noteIndex + shifter][cuiToIndex[cui]] = 1\n",
    "    return bagOfCuisCount, bagOfCuisExist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfCuisCount, bagOfCuisExist = populateWordCountAndExistence(bagOfCuisCount, bagOfCuisExist, mod_note_to_cuis)\n",
    "bagOfCuisCount, bagOfCuisExist = populateWordCountAndExistence(bagOfCuisCount, bagOfCuisExist, nomod_note_to_cuis, len(mod_note_to_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cuis (include duplicates) extracted in each notes:\n",
      " [102.   8.  63.  60.  73. 177. 129.  24.  63.   1.  23.   5.   9. 207.\n",
      "  28.  48.  15.  44.  42.  94.  79.  37.  21.  57.   0.  78.  22.  19.\n",
      " 121. 155.  36.  68. 124.  44. 367.  38.  35. 140.  94.  37.  71.  23.\n",
      "  12. 248.   5.  42.   6.  22. 276. 131.  10.  45.  22. 569.  54. 365.\n",
      " 226.  78. 125.  74.]\n"
     ]
    }
   ],
   "source": [
    "print(\"number of cuis (include duplicates) extracted in each notes:\\n\", bagOfCuisCount.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cuis extracted in each notes:\n",
      " [29. 14. 14.  7.  1. 17. 20.  5.  5.  4.  3. 18.  6.  9. 15. 21.  1. 15.\n",
      " 17.  0. 19. 16. 10. 15. 20.  2.  3.  5.  0.  9.  4.  4. 19. 16.  3. 14.\n",
      " 15. 35. 17.  8.  7.  3. 47. 35.  9. 11. 20.  5.  7.  7.  1.  1. 13. 17.\n",
      " 18. 32. 31.  5. 14.  5.  4.  9.  5. 15. 33.  1.  0.  2.  2.  6.  0. 17.\n",
      " 30. 21. 27. 23. 26.  2. 22.  6.  6.  4. 29. 12. 59.  0. 16. 29.  0. 13.\n",
      " 10.  5.  9. 24. 19. 33. 11.  5. 45. 51. 28. 17.  4. 11. 24. 21. 10.  4.\n",
      " 20.  8.  2. 16. 36.  3. 19. 14. 30.  8.  5.  7. 15. 32. 23. 10. 12. 18.\n",
      "  3. 39.  9. 34.  6.  8. 17.  0. 10.  0. 29. 14. 12. 24.  8.  3. 30. 21.\n",
      " 16. 29. 21.]\n"
     ]
    }
   ],
   "source": [
    "print(\"number of cuis extracted in each notes:\\n\", bagOfCuisExist.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocWithWordx = bagOfCuisExist.sum(0) # 9708\n",
    "\n",
    "def getTFIDF(bagOfCuisCount, bagOfCuisExist):\n",
    "    rows = len(mod_texts) + len(nomod_texts) # 185\n",
    "    cols = len(allCuisList)\n",
    "    tfidf = np.zeros((rows, cols))\n",
    "    for i in range(rows):\n",
    "        totalInDoc = bagOfCuisCount[i].sum() # total cuis in current doc\n",
    "        for j in range(cols):\n",
    "            tfidf[i][j] = bagOfCuisCount[i][j] / (totalInDoc + 0.000001) * np.log(rows/(DocWithWordx[j] + 0.000001))\n",
    "    return tfidf      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 94)\n"
     ]
    }
   ],
   "source": [
    "tfidfVector = getTFIDF(bagOfCuisCount, bagOfCuisExist)\n",
    "print(np.shape(tfidfVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01756008 0.01585284 0.         0.         0.01236403 0.\n",
      " 0.04483177 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02930573 0.03697698\n",
      " 0.02113712 0.07439686 0.         0.00556847 0.00679556 0.01716605\n",
      " 0.01716605 0.00858303 0.00940049 0.         0.         0.\n",
      " 0.         0.05636792 0.1359112  0.         0.02348552 0.00556847\n",
      " 0.         0.         0.01127358 0.00782851 0.         0.\n",
      " 0.         0.         0.01426752 0.         0.01716605 0.01967259\n",
      " 0.00782851 0.01295839 0.         0.02254717 0.         0.02591678\n",
      " 0.         0.         0.         0.         0.01127358 0.01127358\n",
      " 0.         0.         0.01663185 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01359112 0.01029237\n",
      " 0.         0.         0.         0.00983629 0.01295839 0.05707008\n",
      " 0.         0.         0.         0.         0.04498221 0.\n",
      " 0.         0.         0.         0.         0.01077071 0.\n",
      " 0.         0.         0.02654951 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tfidfVector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "modVector = tfidfVector[:len(mod_texts)]\n",
    "nomodVector = tfidfVector[len(mod_texts):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm Distance of tfidf, knn on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_allCuis = collections.Counter() # won't use this.\n",
    "test_allCuis, test_mod_note_to_cuis = getAllCuisAndCuiDict(test_mod_texts, test_allCuis)\n",
    "test_allCuis, test_nomod_note_to_cuis = getAllCuisAndCuiDict(test_nomod_texts, test_allCuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allCuisList, cuiToIndex\n",
    "test_bagOfCuisCount = np.zeros((len(test_mod_texts)+len(test_nomod_texts), len(allCuisList)))\n",
    "test_bagOfCuisExist = np.zeros((len(test_mod_texts)+len(test_nomod_texts), len(allCuisList)))\n",
    "test_bagOfCuisCount, test_bagOfCuisExist = populateWordCountAndExistence(test_bagOfCuisCount, test_bagOfCuisExist, test_mod_note_to_cuis)\n",
    "test_bagOfCuisCount, test_bagOfCuisExist = populateWordCountAndExistence(test_bagOfCuisCount, test_bagOfCuisExist, test_nomod_note_to_cuis, len(test_mod_note_to_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(test_mod_texts)+len(test_nomod_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettestTFIDF(test_bagOfCuisCount, test_bagOfCuisExist):\n",
    "    rows = len(test_mod_texts) + len(test_nomod_texts)\n",
    "    train_rows = len(mod_texts) + len(nomod_texts)\n",
    "    cols = len(allCuisList)\n",
    "    tfidf = np.zeros((rows, cols))\n",
    "    for i in range(rows):\n",
    "        totalInDoc = test_bagOfCuisCount[i].sum() # total cuis in current doc\n",
    "        for j in range(cols):\n",
    "            tfidf[i][j] = test_bagOfCuisCount[i][j] / (totalInDoc + 0.000001) * np.log(train_rows/(DocWithWordx[j] + 0.000001))\n",
    "    return tfidf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 94)\n"
     ]
    }
   ],
   "source": [
    "test_tfidfVector = gettestTFIDF(test_bagOfCuisCount, test_bagOfCuisExist)\n",
    "print(np.shape(test_tfidfVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 0.7188359127892521), (26, 0.7301794830572937), (4, 0.7322129334859062), (54, 0.7365081544182651), (37, 0.736979407639036)]\n",
      "[(19, 0.1518741669842328), (59, 0.17047644364582118), (29, 0.1811957232885321), (57, 0.198684697541227), (25, 0.242484910580776)]\n",
      "[(52, 0.24812984803954616), (6, 0.2599993491617307), (58, 0.3838192307022258), (48, 0.3983529796053539), (23, 0.4056279009125549)]\n"
     ]
    }
   ],
   "source": [
    "# bagOfCuisVector: 185 x 84\n",
    "def getTopKClosest(standardNoteIndex, k):\n",
    "    standard = test_tfidfVector[standardNoteIndex]\n",
    "    minD = float('inf')\n",
    "    closestVecIndex = 0\n",
    "    indexToDis = {}\n",
    "    for i in range(len(tfidfVector)): # 185\n",
    "        vector = tfidfVector[i]\n",
    "        curD = np.linalg.norm(vector - standard)\n",
    "        indexToDis[i] = curD\n",
    "    \n",
    "    return sorted(indexToDis.items(), key = lambda item: item[1])[:k]\n",
    "\n",
    "closest = getTopKClosest(0, 5)\n",
    "print(closest)\n",
    "closest = getTopKClosest(1, 5)\n",
    "print(closest)\n",
    "closest = getTopKClosest(2, 5)\n",
    "print(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "modnomodC = []\n",
    "for note in range(16):\n",
    "    closest = getTopKClosest(note, 5)\n",
    "    mod = np.sum([1 if c[0] < 8 else 0 for c in closest])\n",
    "    nomod = np.sum([1 if c[0] >= 8 else 0 for c in closest])\n",
    "    modnomodC += [(mod, nomod)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (0, 5), (1, 4), (1, 4), (0, 5), (1, 4), (0, 5), (1, 4), (1, 4), (0, 5), (1, 4), (0, 5), (0, 5), (0, 5), (1, 4), (1, 4)]\n"
     ]
    }
   ],
   "source": [
    "print(modnomodC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 8 of mod are determined as mod, 8 / 8 of nomod are determined as nomod in testing\n"
     ]
    }
   ],
   "source": [
    "modClosestToMod = sum([1 if i > j else 0 for i, j in modnomodC[:8]])\n",
    "nomodClosestToNomod = sum([1 if i < j else 0 for i, j in modnomodC[8:]])\n",
    "print(modClosestToMod, \"/ 8 of mod are determined as mod,\", nomodClosestToNomod, \"/ 8 of nomod are determined as nomod in testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04664192 0.02711823 0.01183802 0.01297296 0.0231769  0.05533007\n",
      " 0.00907279 0.01304189 0.00565597 0.02745    0.0236666  0.01672219\n",
      " 0.02178975 0.         0.03801895 0.01917176 0.         0.01362384\n",
      " 0.01710714 0.01449633 0.07824415 0.01343914 0.01023368 0.\n",
      " 0.0146535  0.01803209 0.02725291 0.01357047 0.01314516 0.01596761\n",
      " 0.01411361 0.01682569 0.02279871 0.02298485 0.03102483 0.01738895\n",
      " 0.00913053 0.00658712 0.02780637 0.01331508 0.01302861 0.01238118\n",
      " 0.01881532 0.01339175 0.0381156  0.00425935 0.00275459 0.00852459\n",
      " 0.02971197 0.03522916 0.01671991 0.00974745 0.01632658 0.00649651\n",
      " 0.01485295 0.00404599 0.         0.03629013 0.         0.01475466\n",
      " 0.01046044 0.00922966 0.00947184 0.0070948  0.01319773 0.00337344\n",
      " 0.01403475 0.00904076 0.00981102 0.01216123 0.00667    0.00969748\n",
      " 0.0073153  0.00373023 0.01276019 0.00742153 0.01805468 0.01761033\n",
      " 0.01321059 0.00761546 0.00692041 0.02903941 0.00557114 0.01304988\n",
      " 0.01323478 0.00367696 0.00234513 0.00759392 0.00655743 0.01783081\n",
      " 0.00510055 0.         0.00265731 0.        ]\n"
     ]
    }
   ],
   "source": [
    "meanmod = np.mean(tfidfVector[:69], axis = 0)\n",
    "print(meanmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03776878 0.03117218 0.02006069 0.02119173 0.02134568 0.0001782\n",
      " 0.01427555 0.0091203  0.00802816 0.02180846 0.01473041 0.00887875\n",
      " 0.02475695 0.01006132 0.01747768 0.02645841 0.02625764 0.02858736\n",
      " 0.02644301 0.02071433 0.03474535 0.02018446 0.01835392 0.0076296\n",
      " 0.01776557 0.01415434 0.01703896 0.01033565 0.02310715 0.00535389\n",
      " 0.01493466 0.02495605 0.02445906 0.01574882 0.01295164 0.02195143\n",
      " 0.0189903  0.01238984 0.01421581 0.00641351 0.01567389 0.02568638\n",
      " 0.01966146 0.01070985 0.01724735 0.02521056 0.00968343 0.00992108\n",
      " 0.01201594 0.04899778 0.0123385  0.00936383 0.01313216 0.00539531\n",
      " 0.00752195 0.01502999 0.00462915 0.01344972 0.00427135 0.01255398\n",
      " 0.01303493 0.00756795 0.01729577 0.02094774 0.01031298 0.01748196\n",
      " 0.008648   0.01282777 0.01320011 0.010026   0.01278863 0.01528729\n",
      " 0.00683802 0.01999439 0.00680851 0.01567281 0.01390958 0.0195427\n",
      " 0.02388829 0.00844128 0.00861025 0.00758433 0.0203476  0.01051591\n",
      " 0.01504477 0.02940977 0.01330256 0.01178105 0.00402213 0.01899362\n",
      " 0.00069329 0.         0.00501815 0.00335658]\n"
     ]
    }
   ],
   "source": [
    "meannomod = np.mean(tfidfVector[69:], axis = 0)\n",
    "print(meannomod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'day', 'tablet', 'tab', 'medication', '/', 'mouth', 'refill', 'supply', 'pain', 'negative', 'expiration', 'report', 'release', 'review', 'pulse', '|', 'eval', 'deny', 'month', 'veteran', 'male', 'plan', 'qty', 'intact', 'skin', 'symptom', 'week', 'stable', 'outpt', 'year', 'level', 'alert', 'time', 'discharge', 'p', 'treatment', 'test', 'state', 'daily', 'specimen', 'answer', 'blood pressure', 'change', 'admission', 'blood', 'provider', 'collection', 'risk', 'nurse', 'lab', 'soft', 'history', 'active', 'hyperlipidemia', 'dose', 'status active', 'result', 'status discontinue', 'problem', 'unit', 'hour', 'htn', 'evaluation', 'date', 'mmol', 'mild', 'response', 'pcp', 'hypertension', 'increase', 'eye', 'egfr', 'urine', 'moderate', 'fever', 'diagnosis', 'admit', 'resp', 'evidence', 'allergy', 'stroke', 'assessment', 'lung', 'caregiver', 'neg', 'auto', '9', 'heart', 'respiration', 'atrial fibrillation', 'aneurysm', 'smoke', 'head trauma']\n"
     ]
    }
   ],
   "source": [
    "print(allCuisList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanmod_df = pd.DataFrame(meanmod)\n",
    "meanmod_df.to_csv('mod_mean_tfidf_n.csv')\n",
    "meannomod_df = pd.DataFrame(meannomod)\n",
    "meannomod_df.to_csv('nomod_mean_tfidf_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cuis_df = pd.DataFrame(allCuisList)\n",
    "top_cuis_df.to_csv('top_cuis_tfidf_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVector_df = pd.DataFrame(tfidfVector)\n",
    "tfidfVector_df.to_csv('tfidf_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_w_word_x_df = pd.DataFrame(DocWithWordx)\n",
    "doc_w_word_x_df.to_csv('word_count_train_corpus_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
