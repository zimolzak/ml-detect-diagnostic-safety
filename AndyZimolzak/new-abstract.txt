% Machine Learning for Enhanced Electronic Trigger Detection of Diagnostic Error in the Emergency Department

Andrew J. Zimolzak, Max Yu, Angela Wu, Li Wei, Devika Subramanian,
Usman Mir, Ashish Gupta, Viral Vaghani, Adel Hassan, Hardeep Singh

# Background

Electronic triggers have been used extensively to identify instances
of potential diagnostic error, but largely they identify patterns
suggestive but not definitive. Expert chart review is ordinarily
required to separate e-trigger outputs into true and false instances
of missed opportunities. E-triggers have varying degrees of predictive
value: sometimes quite low. They are often crafted from first
principles, rather than based on empiric data patterns. Machine
learning is a promising approach to append to a rules-based trigger
tool, to enhance predictive value for detecting missed opportunities.
Therefore, we sought to create a machine learning classifier to
emulate human chart reviewers at larger scale, separating e-trigger
output into true and false missed opportunities for diagnosis.

# Methods

Based on the input of an expert panel, we designed several rules-based
electronic triggers to find patterns suggestive of a missed
opportunity in diagnosis, in the emergency department setting.
Triggers included missed follow-up on laboratory results, return
visits of patients with high-risk features at the initial visit,
return visits with a concerning diagnosis related to initial chief
concern, and return visits with hospital admission in general.

For this study we focus on stroke with high-risk features, and
abdominal pain with high-risk features.

Trained clinicians reviewed a random sample of charts for each
e-trigger and labeled each as MOD or no MOD. Labeled charts were used
to train $\ell^1$ regularized logistic regression, as well as $x, y,
z$ methods. Candidate features were demographics, lab values of $a, b,
c$, vital signs, medications, and past history based on encounter
diagnoses, from ER encounter 1 and 2.

Machine learning was iteratively developed by constructing features
thought to be of highest clinical value in identifying MODs, followed
by inspecting cases misclassified by ML, and the particular features
mentioned by chart reviewers as salient to MOD or no MOD.

# Results

Chart review showed $p$ positive predictive value (PPV) for the stroke
trigger, and $q$ PPV for abdominal pain. Inter-rater reliability was
good. For stroke, the best performing ML filter improved PPV to $r$,
missing $s$ percent of true cases. For abdominal pain, the best ML
improved PPV to $t$, missing $u$ percent of cases.

Net reclassification index?

If applied at scale, the ML-enhanced triggers would flag 1234 cases
instead of 4321, where 1000 / 1234 are true MODs, rather than 1111 /
4321.

# Conclusions

We applied machine learning as a second stage to electronic trigger
tools for missed opportunities. We found improved predictive value
while missing relatively few cases of true MOD. This technique can be
applied to multiple other rules-based e-triggers for diagnostic error.
