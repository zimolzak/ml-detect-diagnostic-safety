{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_colwidth\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_CATALOG</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_cohort</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_04_04_Lab</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_08_AllMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_08_Consult</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_12_ICD</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_14_Vital</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201622_30_Note_withRole</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_16_HF</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_Demorgraphics</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TABLE_CATALOG TABLE_SCHEMA  \\\n",
       "0   ORD_Singh_201911038D         Dflt   \n",
       "1   ORD_Singh_201911038D         Dflt   \n",
       "2   ORD_Singh_201911038D         Dflt   \n",
       "3   ORD_Singh_201911038D         Dflt   \n",
       "4   ORD_Singh_201911038D         Dflt   \n",
       "5   ORD_Singh_201911038D         Dflt   \n",
       "6   ORD_Singh_201911038D         Dflt   \n",
       "7   ORD_Singh_201911038D         Dflt   \n",
       "8   ORD_Singh_201911038D         Dflt   \n",
       "9   ORD_Singh_201911038D         Dflt   \n",
       "10  ORD_Singh_201911038D         Dflt   \n",
       "11  ORD_Singh_201911038D         Dflt   \n",
       "12  ORD_Singh_201911038D         Dflt   \n",
       "13  ORD_Singh_201911038D         Dflt   \n",
       "\n",
       "                                                     TABLE_NAME  TABLE_TYPE  \n",
       "0                           _B00_ML4TrgPos_Y201621_01_04_cohort  BASE TABLE  \n",
       "1                              _B00_ML4TrgPos_Y201621_05_04_Rad  BASE TABLE  \n",
       "2                              _B00_ML4TrgPos_Y201621_04_04_Lab  BASE TABLE  \n",
       "3                     _B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat  BASE TABLE  \n",
       "4                     _B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed  BASE TABLE  \n",
       "5           _B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug  BASE TABLE  \n",
       "6                       _B00_ML4TrgPos_Y201621_06_Med_08_AllMed  BASE TABLE  \n",
       "7                             _B00_ML4TrgPos_Y201621_08_Consult  BASE TABLE  \n",
       "8                                 _B00_ML4TrgPos_Y201621_12_ICD  BASE TABLE  \n",
       "9                               _B00_ML4TrgPos_Y201621_14_Vital  BASE TABLE  \n",
       "10                      _B00_ML4TrgPos_Y201622_30_Note_withRole  BASE TABLE  \n",
       "11                                 _B00_ML4TrgPos_Y201621_16_HF  BASE TABLE  \n",
       "12                   _B00_ML4TrgPos_Y201621_01_04_Demorgraphics  BASE TABLE  \n",
       "13  _B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter  BASE TABLE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cohort', 'Rad', 'Lab', 'RxOutpat', 'NonVAMed', 'Consult', 'ICD', 'withRole', 'Demorgraphics', 'Only10daysPrior30DaysAfter'])\n"
     ]
    }
   ],
   "source": [
    "import dizzy_util as util\n",
    "dataset = util.extractDataset(\"B00_ML4TrgPos_Y2016\", {\"Note\", \"AllMed\", \"Vital\", \"HF\", \"DispensedDrug\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df, label_map = util.retrieveLabels()\n",
    "label_df = util.convertLabelMap(label_map)\n",
    "datasubset = util.extractAndStandarizeCohort(dataset, \"Dizziness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasubset[\"cohort\"] = datasubset[\"cohort\"].merge(label_df.rename(columns={\"PatientSSN\":\"patientSSN\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasubset['cohort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_visit_pts = np.extract(datasubset['cohort']['patientSSN'].value_counts() == 1, datasubset['cohort']['patientSSN'].value_counts().index)\n",
    "multi_visit_pts = np.extract(datasubset['cohort']['patientSSN'].value_counts() > 1, datasubset['cohort']['patientSSN'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_visit_cohort = datasubset['cohort'][datasubset['cohort']['patientSSN'].isin(single_visit_pts)]\n",
    "multi_visit_cohort  = datasubset['cohort'][datasubset['cohort']['patientSSN'].isin(multi_visit_pts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_w_ed_start = datasubset['withRole'].merge(single_visit_cohort, left_on='PatientSSN', right_on='patientSSN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for visit in multi_visit_cohort.iterrows():\n",
    "    print(visit)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dizziness_df['PtSSN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasubset['cohort'].dropna(subset=['studyID'])['patientSSN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoMOD       44\n",
       "MOD         38\n",
       "PMOD        12\n",
       "CodingEr     6\n",
       "Name: DxErrorERCoded, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizziness_df['DxErrorERCoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_w_ed_start = datasubset['withRole'].merge(datasubset['cohort'].dropna(subset=['studyID']), \n",
    "                                               left_on='PatientSSN', right_on='patientSSN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasubset['cohort'][~pd.isna(datasubset['cohort']['studyID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import get_texts\n",
    "importlib.reload(get_texts)\n",
    "from get_texts import get_texts\n",
    "\n",
    "report_texts = get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    36\n",
       "True     32\n",
       "Name: MOD, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_texts['MOD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df = pd.read_csv(open(\"Viral_data/ML4_HighRisk_Dizziness/labels-Dizziness.csv\", 'r', errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoMOD       44\n",
       "MOD         38\n",
       "PMOD        12\n",
       "CodingEr     6\n",
       "Name: DxErrorERCoded, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizziness_df['DxErrorERCoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_CATALOG</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_cohort</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_04_04_Lab</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_06_Med_08_AllMed</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_08_Consult</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_12_ICD</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_14_Vital</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201622_30_Note_withRole</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_16_HF</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_01_04_Demorgraphics</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORD_Singh_201911038D</td>\n",
       "      <td>Dflt</td>\n",
       "      <td>_B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TABLE_CATALOG TABLE_SCHEMA  \\\n",
       "0   ORD_Singh_201911038D         Dflt   \n",
       "1   ORD_Singh_201911038D         Dflt   \n",
       "2   ORD_Singh_201911038D         Dflt   \n",
       "3   ORD_Singh_201911038D         Dflt   \n",
       "4   ORD_Singh_201911038D         Dflt   \n",
       "5   ORD_Singh_201911038D         Dflt   \n",
       "6   ORD_Singh_201911038D         Dflt   \n",
       "7   ORD_Singh_201911038D         Dflt   \n",
       "8   ORD_Singh_201911038D         Dflt   \n",
       "9   ORD_Singh_201911038D         Dflt   \n",
       "10  ORD_Singh_201911038D         Dflt   \n",
       "11  ORD_Singh_201911038D         Dflt   \n",
       "12  ORD_Singh_201911038D         Dflt   \n",
       "13  ORD_Singh_201911038D         Dflt   \n",
       "\n",
       "                                                     TABLE_NAME  TABLE_TYPE  \n",
       "0                           _B00_ML4TrgPos_Y201621_01_04_cohort  BASE TABLE  \n",
       "1                              _B00_ML4TrgPos_Y201621_05_04_Rad  BASE TABLE  \n",
       "2                              _B00_ML4TrgPos_Y201621_04_04_Lab  BASE TABLE  \n",
       "3                     _B00_ML4TrgPos_Y201621_06_Med_04_RxOutpat  BASE TABLE  \n",
       "4                     _B00_ML4TrgPos_Y201621_06_Med_07_NonVAMed  BASE TABLE  \n",
       "5           _B00_ML4TrgPos_Y201621_06_Med_05_BCMA_DispensedDrug  BASE TABLE  \n",
       "6                       _B00_ML4TrgPos_Y201621_06_Med_08_AllMed  BASE TABLE  \n",
       "7                             _B00_ML4TrgPos_Y201621_08_Consult  BASE TABLE  \n",
       "8                                 _B00_ML4TrgPos_Y201621_12_ICD  BASE TABLE  \n",
       "9                               _B00_ML4TrgPos_Y201621_14_Vital  BASE TABLE  \n",
       "10                      _B00_ML4TrgPos_Y201622_30_Note_withRole  BASE TABLE  \n",
       "11                                 _B00_ML4TrgPos_Y201621_16_HF  BASE TABLE  \n",
       "12                   _B00_ML4TrgPos_Y201621_01_04_Demorgraphics  BASE TABLE  \n",
       "13  _B00_ML4TrgPos_Y201621_05_04_Rad_Only10daysPrior30DaysAfter  BASE TABLE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cohort', 'Rad', 'Lab', 'RxOutpat', 'NonVAMed', 'Consult', 'ICD', 'withRole', 'Demorgraphics', 'Only10daysPrior30DaysAfter'])\n"
     ]
    }
   ],
   "source": [
    "import dizzy_util as util\n",
    "dataset = util.extractDataset(\"B00_ML4TrgPos_Y2016\", {\"Note\", \"AllMed\", \"Vital\", \"HF\", \"DispensedDrug\"})\n",
    "\n",
    "dizziness_df, label_map = util.retrieveLabels() # labeled\n",
    "label_df = util.convertLabelMap(label_map)\n",
    "datasubset = util.extractAndStandarizeCohort(dataset, \"Dizziness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoMOD       44\n",
       "MOD         38\n",
       "PMOD        12\n",
       "CodingEr     6\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36 + 32 + 24 + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "44 + 38 + 12 + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasubset[\"cohort\"] = datasubset[\"cohort\"].merge(label_df.rename(columns={\"PatientSSN\":\"patientSSN\"}))\n",
    "len(datasubset[\"cohort\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_w_ed_start = datasubset['withRole'].merge(datasubset['cohort'].dropna(subset=['studyID']), \n",
    "                                               left_on='PatientSSN', right_on='patientSSN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubset(ds, subsetNames):\n",
    "    pkeys = util.getPrimaryKeys(dataset)\n",
    "    cohort_key = pkeys[\"cohort\"]\n",
    "    cohort_subset = ds[\"cohort\"][ds[\"cohort\"].Label.isin(subsetNames)]\n",
    "    ids = pd.DataFrame({cohort_key: cohort_subset[cohort_key].unique()})\n",
    "    dss = dict()\n",
    "    for table, df in ds.items():\n",
    "        dss[table] = ids.merge(df, how=\"inner\", left_on=cohort_key, right_on=pkeys[table])\n",
    "        if pkeys[table] != cohort_key:\n",
    "            dss[table] = dss[table].drop([cohort_key], axis = 1)\n",
    "        dss[table][pkeys[table]] = dss[table][pkeys[table]].astype(int)\n",
    "    return dss\n",
    "\n",
    "# datasubset['withRole'] = datasubset['withRole'][datasubset['withRole']['DuringVisit']]\n",
    "\n",
    "modsubset = extractSubset(datasubset, [\"MOD\"]) # dizziness MOD cases\n",
    "nomodsubset = extractSubset(datasubset, [\"NoMOD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasubset['cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modsubset['cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(modsubset['cohort']['patientSSN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nomodsubset['cohort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(nomodsubset['cohort']['patientSSN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhysician(df):\n",
    "    return df[(df['ProviderRole'] == 'Allopathic & Osteopathic Physicians') & (df['TIUStandardTitle'] != 'ADDENDUM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ed_or_physician_df = getPhysician(modsubset['withRole']).sort_values(\"EntryDateTime\")\n",
    "nomod_ed_or_physician_df = getPhysician(nomodsubset['withRole']).sort_values(\"EntryDateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_texts = mod_ed_or_physician_df.groupby('PatientSSN').aggregate(lambda seq: '\\n<ENDNOTE>\\n'.join(seq))\n",
    "nomod_ed_or_physician_df.loc[:,'ReportText'] = nomod_ed_or_physician_df['ReportText'].fillna('')\n",
    "nomod_texts = nomod_ed_or_physician_df.groupby('PatientSSN').aggregate(lambda seq: '\\n<ENDNOTE>\\n'.join(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mod_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nomod_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_w_ed_start = note_w_ed_start.set_index('TIUDocumentSID', drop=False)\n",
    "datasubset['withRole'] = datasubset['withRole'].set_index('TIUDocumentSID', drop=False)\n",
    "datasubset['withRole']['DuringVisit'] = (note_w_ed_start['EntryDateTime'] >= note_w_ed_start['EDStartDateTime']) & (note_w_ed_start['EntryDateTime'] <= note_w_ed_start['EDEndDateTime'])\n",
    "datasubset['withRole'] = datasubset['withRole'][datasubset['withRole']['DuringVisit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsubset = extractSubset(datasubset, [\"MOD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(modsubset['withRole']['PatientSSN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(nomodsubset['withRole']['PatientSSN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(nomodsubset['cohort']['patientSSN'], nomodsubset['withRole']['PatientSSN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dizziness_df[['CaseSummaryER', 'DxErrorERCoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "mod_texts = dizziness_df[dizziness_df['DxErrorERCoded'] == 'MOD']\n",
    "nomod_texts = dizziness_df[dizziness_df['DxErrorERCoded'] == 'NoMOD']\n",
    "texts = pd.concat([mod_texts, nomod_texts]).reset_index(drop=True)\n",
    "accs = []\n",
    "for train_indices, test_indices in kf.split(texts['CaseSummaryER']):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(vectorizer.fit_transform(texts['CaseSummaryER'][train_indices]), texts['DxErrorERCoded'][train_indices])\n",
    "    x_test = vectorizer.transform(texts['CaseSummaryER'][test_indices])\n",
    "    y_test = texts['DxErrorERCoded'][test_indices]\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc = accuracy_score(texts['DxErrorERCoded'][test_indices], y_pred)\n",
    "    print(acc)\n",
    "    accs.append(acc)\n",
    "    \n",
    "    imp = clf.coef_[0]\n",
    "    word_lookup = {index: word for word,index in vectorizer.vocabulary_.items()}\n",
    "    df_lookup = pd.DataFrame(word_lookup.values(), index=word_lookup.keys(), columns=['Word'])\n",
    "    features = df_lookup['Word']\n",
    "    sorted_idx = imp.argsort()\n",
    "    sorted_idx = np.concatenate([sorted_idx[:10], sorted_idx[-10:]])\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6, 8)\n",
    "    ax.barh(features[sorted_idx], imp[sorted_idx])\n",
    "    ax.set_xlabel('Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dizziness_df['CaseSummaryER'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dizziness_df['CaseSummaryER'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dizziness_df['CaseSummaryER'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dizziness_df['CaseSummaryER'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dizziness_df['CaseSummaryER'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_analysis(fulltext):\n",
    "    paragraphs = fulltext.split('\\n\\n')\n",
    "    try:\n",
    "        return paragraphs[0]+'\\n\\n'+paragraphs[1]\n",
    "    # if there are no paragraphs\n",
    "    except IndexError as e:\n",
    "        return fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df['CaseSummaryAbridged'] = dizziness_df['CaseSummaryER'].map(strip_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "mod_texts = dizziness_df[dizziness_df['DxErrorERCoded'] == 'MOD']\n",
    "nomod_texts = dizziness_df[dizziness_df['DxErrorERCoded'] == 'NoMOD']\n",
    "texts = pd.concat([mod_texts, nomod_texts]).reset_index(drop=True)\n",
    "accs = []\n",
    "for train_indices, test_indices in kf.split(texts['CaseSummaryAbridged']):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(vectorizer.fit_transform(texts['CaseSummaryAbridged'][train_indices]), texts['DxErrorERCoded'][train_indices])\n",
    "    x_test = vectorizer.transform(texts['CaseSummaryAbridged'][test_indices])\n",
    "    y_test = texts['DxErrorERCoded'][test_indices]\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc = accuracy_score(texts['DxErrorERCoded'][test_indices], y_pred)\n",
    "    print(acc)\n",
    "    accs.append(acc)\n",
    "    \n",
    "    imp = clf.coef_[0]\n",
    "    word_lookup = {index: word for word,index in vectorizer.vocabulary_.items()}\n",
    "    df_lookup = pd.DataFrame(word_lookup.values(), index=word_lookup.keys(), columns=['Word'])\n",
    "    features = df_lookup['Word']\n",
    "    sorted_idx = imp.argsort()\n",
    "    sorted_idx = np.concatenate([sorted_idx[:10], sorted_idx[-10:]])\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6, 8)\n",
    "    ax.barh(features[sorted_idx], imp[sorted_idx])\n",
    "    ax.set_xlabel('Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_ctx(series, phrase):\n",
    "    ctx = series.str.extract(r\"([\\s\\S]{0,50}\" + phrase + \"[\\s\\S]{0,50})\", flags=re.IGNORECASE | re.MULTILINE)\n",
    "    return ctx[~ctx[0].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ctx(dizziness_df['CaseSummaryAbridged'], 'alarm symptoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df.loc[get_ctx(dizziness_df['CaseSummaryAbridged'], 'alarm symptoms').index]['DxErrorERCoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizziness_df.columns[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_ctx(dizziness_df['CaseSummaryAbridged'], 'noted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the highest-yield things for us to do are to look for alarm sx and incomplete physical exam. Let's start with physical exam because I think it's a little easier to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ctx(dizziness_df['CaseSummaryAbridged'], 'exam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = dizziness_df.merge(report_texts, left_on='PtSSN', right_on='PatientSSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined.loc[4]['CaseSummaryER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined.loc[3]['ReportText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_ctx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-4ecd303d8002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_combined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ReportText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hints'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_ctx' is not defined"
     ]
    }
   ],
   "source": [
    "get_ctx(df_combined['ReportText'], 'hints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signs.loc[2,'HEADACHE-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"[\\s\\S]{,50}\\bha\\b[\\s\\S]{,50}\", df_combined.loc[41,'ReportText'], flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df_combined.loc[2,'ReportText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medspacy.visualization import visualize_ent\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.loc[2,'ReportText'].find('-HA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.loc[2,'ReportText'][4193:4196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.char_span(4194, 4196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for text in df_combined['ReportText']:\n",
    "    results = re.findall(r'hee?nt:[^:]+?(?=.+:)', text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    print(\"<>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = {\n",
    "    'paresthesia': ['paresthesias', 'no paresthesias', 'tingling'],\n",
    "    'weakness': ['weakness', '+weakness', 'denies acute upper or lower extremities weakness', '+ve weakness'],\n",
    "    'numbness': ['numbness', '-numbness', 'loss of sensation', 'saddle anesthesia'],\n",
    "    'facial droop': ['no facial droop'],\n",
    "    'dysphagia': ['difficulty swallowing', 'dysphagia'],\n",
    "    'dizziness': ['dizziness (now resolved)', '+dizziness'],\n",
    "    'vision change': ['new vision or speech changes', 'va 20/200 in each eye', '-vision changes', '+blurry vision', 'no visual disturbance', 'visual changes'],\n",
    "    'hearing change': ['hearing loss'],\n",
    "    'tinnitus': ['tinnitus'],\n",
    "    'nystagmus': ['no nystagmus'],\n",
    "    'speech': ['new vision or speech changes'],\n",
    "    'headache': ['severe sudden headache', r'headache\\s+\\[\\s+\\]', 'headaches', '+ headaches', '-ha', 'no headache'],\n",
    "    'syncope': ['syncope', 'loc'],\n",
    "    'incontinence': ['loss of bowel or bladder control'],\n",
    "    'fall': ['falls'],\n",
    "    'memory loss': ['no memory problems']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_components = {\n",
    "    'Mental Status': [\n",
    "#         'alert and oriented', \n",
    "#         'alert oriented',\n",
    "        'alert, oriented x 3', \n",
    "        'alert and oriented x3',\n",
    "        'a+ox3',\n",
    "        'a+o x 3',\n",
    "        'a&ox3',\n",
    "        'aao x 3',\n",
    "        'a,a,ox3',\n",
    "        'AOx4', 'a&ox4', \n",
    "#         'normal mentation',\n",
    "#         'conversant, unaltered'\n",
    "    ],\n",
    "    'Cranial Nerves': [\n",
    "        'cn ii-xii intact',\n",
    "        'cnii-xii grossly intact',\n",
    "        'cn ii-xii grossly intact',\n",
    "#         'c2-c12 intact',\n",
    "        'cn2-12 wnl',\n",
    "        'cn 2-12 intact',\n",
    "#         'cn 2-12i',\n",
    "        'cn grossly intact',\n",
    "        'cranial nerves ii-xii intact',\n",
    "        'cranial nerves ii-xii grossly intact',\n",
    "        'cranial nerves are intact',\n",
    "        'cranial nerves intact',\n",
    "        'cranials ii-xii intact',\n",
    "#         'ii-xii grossly intact',\n",
    "        'normal cranial nerves',\n",
    "#         'no gross deficits in cranial nerve function', \n",
    "#         'normal shoulder shrugging'\n",
    "    ],\n",
    "    'Pupils': [\n",
    "        'perrla', \n",
    "        'perrl', \n",
    "        'perla', \n",
    "        'pupils equal, round reactive to light',\n",
    "        'pupils are equal, round, and reactive to light and accommodation',\n",
    "        'pupils - equal, round, reactive to light', 'pupils equal, round, and reactive tolight'\n",
    "    ],\n",
    "    'EOM': [\n",
    "        'eomi', \n",
    "        'extraocular muscles are intact', \n",
    "        'extra occular movement intact',\n",
    "#         'w/ lateral nystagmus only', \n",
    "#         'patient has nystagmus',\n",
    "    ],\n",
    "    'Vision': [\n",
    "        'Visual fields reveal a left homonymous hemianopsia'\n",
    "    ],\n",
    "    'Focal deficits': [\n",
    "        'no focal deficits', \n",
    "        'grossly non-focal',\n",
    "        'without any focal deficits',\n",
    "        'no focal neuro deficits', \n",
    "        'nonfocal', \n",
    "        'non-focal', \n",
    "        'non focal',\n",
    "    ],\n",
    "    'Reflexes': [\n",
    "        'reflexes 2/4 throughout', \n",
    "#         'babinski neg', \n",
    "        \"dtr's 2+ bilaterally symmetric\"\n",
    "    ],\n",
    "    'Motor Extremities': [\n",
    "        'strength 5/5 b/l upper and lower ext', \n",
    "        'strength 5/5 bilaterally',\n",
    "        'strength 5/5 and symmetric',\n",
    "        'motor 5/5 in all 4 extremities',\n",
    "        '5/5 strength in all ext',\n",
    "        '5/5 strength to bilateral hand grip, arm flexion/extension, hip flexion/extension, leg extension/flexion, great toe dorsiflexion, foot plantar/dorsiflexion',\n",
    "        'muscle strength 5/5 and symmetric in ue/le',\n",
    "        'motor strength 5/5 in all extremities',\n",
    "        'strength 5/5 in bl upper and lower extremities',\n",
    "        'normal motor and sensory (except neuropathy to feet bilateral)'\n",
    "        'motor/sensor grossly intact',\n",
    "        'no sensory or motor deficit',\n",
    "        'no focal sensory or motor deficits',\n",
    "        'no focal motor deficits',\n",
    "#         'nl strength/sensation x 4 extremities',\n",
    "        'normal motor function',\n",
    "#         'normal extension rise of upper extremities',\n",
    "#         'slightly decreased strength to grip, flexion and extension of the right upper extremity, 4/5',\n",
    "#         'leg lift strength is 5 over 5 bilaterally',\n",
    "#         'dorsiflexion is 5/5 bilaterally',\n",
    "#         'plantar flexion on the right is slightly decreased compared to the left',\n",
    "#         'no movement deficits',\n",
    "        'strength equal & adequate',\n",
    "        'strength 4/5 symmetric ue & le',\n",
    "#         'appearing weak',\n",
    "#         'patient has some weakness to the left arm and left leg',\n",
    "        'motor 5/5'\n",
    "    ],\n",
    "    'Motor Face': [\n",
    "        'face\\r\\nsymmetric',\n",
    "        'no facial droop appreciated',\n",
    "        'no facial droop', \n",
    "        'no focal facial asymmetry', \n",
    "        'normal facial movements and symmetry'\n",
    "    ],\n",
    "    'Sensation': [\n",
    "        'normal motor and sensory (except neuropathy to feet bilateral)'\n",
    "        'motor/sensor grossly intact', \n",
    "        'no sensory or motor deficit',\n",
    "        'no focal sensory or motor deficits',\n",
    "        'nl strength/sensation x 4 extremities',\n",
    "        'sensation intact', \n",
    "        'sensation\\ngrossly intact in ue/le', \n",
    "        'normal sensation',\n",
    "        'mild sensory def to soft touch',\n",
    "        'sensation intact to light touch in the face',\n",
    "        'sensation intact below the head',\n",
    "        'no sensory deficits',\n",
    "        'sensory intact'],\n",
    "    'Speech': ['speech clear and appropriate', 'speech clear', 'no slurred speech', 'normal speech'],\n",
    "    'Gait': ['gait wnl', 'gait appears to be normal', 'gait steady', 'normal gait', 'gait normal', 'no ataxia', 'nl steady gait with no ataxia'],\n",
    "    'Proprioception': [\n",
    "        'negative rhomberg', \n",
    "        'Rhomber negative', \n",
    "        'neg romberg', \n",
    "        'negative pronator drift', \n",
    "        'pronator drift negative',\n",
    "    ],\n",
    "    'Cerebellar': [\n",
    "        'finger to nose WNL bilaterally',\n",
    "        'finger-nose normal',\n",
    "        'normal finger to nose, heel to shin, rapid alternating movements',\n",
    "        'normal finger to nose bilat',\n",
    "#         'normal heel to shin bilat',\n",
    "#         'heel-shin', \n",
    "#         'no dysmetria or past-pointing', \n",
    "        'the patient is slightly slower and finger to nose movements with the right upper extremity',\n",
    "        'normal cerebellar function f-n-f',\n",
    "        'good finer to nose and rapid alternating movements',\n",
    "        'finger-to-nose and ram intact'\n",
    "    ],\n",
    "    'Dix-Hallpike': ['dix hall pike w/o dizziness or nystagmus']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_sx = {\n",
    "    'vision changes': ['vision changes', 'blurred vision', 'blurry vision', 'changes in vision', 'change in vision', 'visual changes', 'worsening vision', 'blurring of the vision', 'vision has blurred'],\n",
    "    'chest pain': ['chest pain', 'cp'],\n",
    "    'headache': ['ha', 'headache'],\n",
    "    'nuchal rigidity': ['stiff neck', 'neck stiffness', 'neck pain or stiffness', 'nuchal rigidity'],\n",
    "    'fever': ['fever','fevers'],\n",
    "    'LOC': ['loc', 'loss of \\r\\nconsciousness'],\n",
    "    'vomiting': ['vomit', 'vomiting', 'emesis'],\n",
    "    'palpitations': ['palp', 'palpitation', 'palpitations'],\n",
    "    'walk': ['able to walk', 'can walk', 'unable to walk'],\n",
    "    r\"(?P<VISION_CHANGES>vis(?:ion|ual)\\schanges?|changes?\\sin\\svision|blurr(?:ed|y)\\svision)|blurring.{,10}vision\",\n",
    "    r\"(?P<CHEST_PAIN>chest pain|cp)\",\n",
    "    r\"(?P<HEADACHE>headache|\\bha\\b)\",\n",
    "    r\"(?P<FEVER>fevers?)\",\n",
    "    r\"(?P<NUCHAL_RIGIDITY>neck\\sstiffness|stiff\\sneck|neck\\spain\\sor\\sstiffness)\",\n",
    "    r\"(?P<LOC>\\bloc\\b|loss\\sof\\sconsciousness)\",\n",
    "    r\"(?P<VOMITING>vomit(?:ing)?)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "import medspacy\n",
    "from medspacy.context import ConTextRule\n",
    "from medspacy.section_detection import SectionRule\n",
    "import regex as fuzzy\n",
    "import re\n",
    "\n",
    "def nlp(proc):\n",
    "    nlp_ = medspacy.load()\n",
    "    ctx = nlp_.get_pipe('medspacy_context')\n",
    "    nlp_.disable_pipe('medspacy_target_matcher')\n",
    "    # we have to run ctx separately since we're using regex for target matching\n",
    "    nlp_.disable_pipe('medspacy_context')\n",
    "    \n",
    "    ctx_rules = [\n",
    "        ConTextRule(\"Negative\", category=\"NEGATED_EXISTENCE\", direction=\"FORWARD\"),\n",
    "        ConTextRule(\"Negative\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"Neg\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"None\", category=\"NEGATED_EXISTENCE\", direction=\"BACKWARD\"),\n",
    "        ConTextRule(\"WNL\", category=\"NEGATED_EXISTENCE\",direction=\"BACKWARD\"),\n",
    "        ConTextRule(\"normal\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"steady\",category= \"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"intact\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"symmetric\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"-\", category=\"NEGATED_EXISTENCE\", pattern=[{\"TEXT\": \"-\"}, {\"LOWER\": \"ve\", \"OP\": \"?\"}], max_scope=1, direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"Denies\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "        ConTextRule(\"Denied\", category=\"NEGATED_EXISTENCE\", direction=\"BIDIRECTIONAL\"),\n",
    "    ]\n",
    "    ctx.add(ctx_rules)\n",
    "    \n",
    "    sectionizer = nlp_.add_pipe(\"medspacy_sectionizer\", config={\"rules\": \"default\"})\n",
    "    section_patterns = [\n",
    "        SectionRule(category=\"medications\", literal=\"medications:\",\n",
    "                    pattern=[\n",
    "                        {\"LOWER\": \"inactive\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"active\", \"OP\": \"?\"}, \n",
    "                        {\"LOWER\": \"non\", \"OP\": \"?\"}, \n",
    "                        {\"TEXT\": \"-\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"va\", \"OP\": \"?\"}, \n",
    "                        {\"LOWER\": \"inpatient\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"outpatient\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"medications\"},\n",
    "                        {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"including\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"excluding\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"supplies\", \"OP\": \"?\"},\n",
    "                        {\"TEXT\": \")\", \"OP\": \"?\"},\n",
    "                        {\"TEXT\": \":\"}]),\n",
    "        SectionRule(category=\"medications\", literal=\"medications status\",\n",
    "                    pattern=[\n",
    "                        {\"LOWER\": \"inactive\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"active\", \"OP\": \"?\"}, \n",
    "                        {\"LOWER\": \"non\", \"OP\": \"?\"}, \n",
    "                        {\"TEXT\": \"-\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"va\", \"OP\": \"?\"}, \n",
    "                        {\"LOWER\": \"inpatient\", \"OP\": \"?\"}, \n",
    "                        {\"LOWER\": \"outpatient\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"medications\"},\n",
    "                        {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"including\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"excluding\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"supplies\", \"OP\": \"?\"},\n",
    "                        {\"TEXT\": \")\", \"OP\": \"?\"},\n",
    "                        {\"LOWER\": \"status\"}]),\n",
    "        SectionRule(category=\"delete\", literal=\"suicide screen:\"),\n",
    "        SectionRule(category=\"delete\", literal=\"suicide screening:\"),\n",
    "        SectionRule(category=\"medications\", literal=\"medication list:\",\n",
    "                   pattern=[{\"LOWER\": {\"REGEX\": \"med(ication?)s?\"}}, {\"LOWER\": \"list\"}, {\"TEXT\": \":\", \"OP\": \"?\"}]),\n",
    "        SectionRule(category=\"medications\", literal=\"meds:\"),\n",
    "        SectionRule(category=\"medications\", literal=\"active outpatient medications\"),\n",
    "        SectionRule(category=\"history\", literal=\"problem list\"),\n",
    "        SectionRule(category=\"keep\", literal=\"total medications\"), # marks end of meds template\n",
    "        SectionRule(category=\"medications\", literal=\"medications upon discharge\"),\n",
    "        SectionRule(category=\"medications\", literal=\"medications/supplies\",\n",
    "                   pattern=[{\"LOWER\": {\"REGEX\": \"med(ication?)s?\"}}, {\"TEXT\": \"/\"}, {\"LOWER\": \"supplies\"},]),\n",
    "        SectionRule(category=\"medications\", literal=\"medications administered:\"),\n",
    "    ]\n",
    "    sectionizer.add(section_patterns)\n",
    "\n",
    "    doc = nlp_(proc)\n",
    "    # requires the a, the o, and the x3/4. conjunction between a and o is optional\n",
    "    matchers = [\n",
    "        r\"(?P<MENTAL_STATUS>a(?:lert)?\\s?(?:[&+a,](?:nd)?)?\\s?o(?:riented)?\\s?x\\s?[34])\",\n",
    "        r\"(?P<CRANIAL_NERVES>(?:cranials|c(?:ranial\\s)?n(?:erves)?)\\s?(?:(?:2|ii)-(?:12|xii)\\s)?(?:are\\s)?(?:grossly\\s)?(?:intact|wnl))\",\n",
    "        r\"(?P<PUPILS>(?:perrla){d<=1}|(?:pupils))\",\n",
    "        r\"(?P<EOM>eomi|extra.?occ?ular\\s(?:muscles|movements?)?\\s(?:are\\s)?intact)\",\n",
    "        r\"(?P<FOCAL_DEFICITS>(?:no\\s)?focal(?:\\s(?:neuro\\s)?deficits?)?|non[ -]?focal)\",\n",
    "        r\"(?P<NYSTAGMUS>nystagmus)\",\n",
    "        r\"(?P<REFLEXES>reflex\\w*|dtrs?)\",\n",
    "        r\"(?P<MOTOR_EXTREMITIES>strength (?:\\d/5|equal)|\\d/5 strength|motor)\",\n",
    "        r\"(?P<MOTOR_FACE>fac(?:e|ial)\\s+(?:\\w+\\s){,2}(?:droop|a?symmetr\\w+))\",\n",
    "        r\"(?P<SENSATION>sensation|sensory)\",\n",
    "        r\"(?P<SPEECH>speech)\",\n",
    "        r\"(?P<GAIT>gait)\",\n",
    "        r\"(?P<ATAXIA>ataxi[ac])\",\n",
    "        r\"(?P<ROMBERG>rh?omberg)\",\n",
    "        r\"(?P<PRONATOR_DRIFT>pronator\\s+drift)\",\n",
    "        r\"(?P<CEREBELLAR>(?:finger(?:-|\\s+|[-\\s]to[-\\s])nose){e<=1}|f-n-f)\",\n",
    "        r\"(?P<DIX_HALLPIKE>dix[-\\s]?hall[ -\\s]?pike)\",\n",
    "        # alarm sx\n",
    "        r\"(?P<VISION_CHANGES>vis(?:ion|ual)\\schanges?|changes?\\sin\\svision|blurr(?:ed|y)\\svision|blurring.{,10}vision)\",\n",
    "        r\"(?P<CHEST_PAIN>chest pain|cp)\",\n",
    "        r\"(?P<HEADACHE>headache|\\bha\\b)\",\n",
    "        r\"(?P<FEVER>fevers?)\",\n",
    "        r\"(?P<NUCHAL_RIGIDITY>neck\\sstiffness|stiff\\sneck|neck\\spain\\sor\\sstiffness)\",\n",
    "        r\"(?P<LOC>\\bloc\\b|loss\\sof\\sconsciousness)\",\n",
    "        r\"(?P<VOMITING>vomit(?:ing)?)\",\n",
    "    ]\n",
    "    allow_plus_minus = [r\"(?<=[+-])?\"+m+r\"(?=[+-])?\" for m in matchers]\n",
    "    # BESTMATCH flag keeps out extra spaces from fuzzy matches\n",
    "    matches = fuzzy.finditer('|'.join(allow_plus_minus), proc, flags=re.IGNORECASE | fuzzy.BESTMATCH)\n",
    "\n",
    "    original_ents = list(doc.ents)\n",
    "    mwt_ents = []\n",
    "    for match in matches:\n",
    "        start, end = match.span()\n",
    "        span = doc.char_span(start, end)\n",
    "        # this makes sure that we only match at token boundaries\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, match.lastgroup))\n",
    "    for start, end, name in mwt_ents:\n",
    "        if name is None:\n",
    "            print('Skipping ent:')\n",
    "            print(start, end, name)\n",
    "            continue\n",
    "        ent_span = Span(doc, start, end, label=name)\n",
    "        original_ents.append(ent_span)\n",
    "    doc.ents = original_ents\n",
    "    \n",
    "    return ctx(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc\n",
    "def get_signs(doc):\n",
    "    signs = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent._.section is not None:\n",
    "            if ent._.section.category == 'medications' or ent._.section.category == 'delete':\n",
    "                continue\n",
    "        if ent._.is_hypothetical or ent._.is_historical:\n",
    "            continue\n",
    "        \n",
    "        has_neg = np.any([mod.category == 'NEGATED_EXISTENCE' for mod in ent._.modifiers])\n",
    "        # 0 = positive (has sign), 1 = negative/normal (no sign), 2 = unsure\n",
    "        status = not has_neg\n",
    "        \n",
    "        # create the array first if needed\n",
    "        if ent.label_ not in signs:\n",
    "            signs[ent.label_] = [0, 0]\n",
    "        signs[ent.label_][status] += 1\n",
    "    return signs\n",
    "        \n",
    "Doc.set_extension(\"signs\", getter=get_signs, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_combined = dizziness_df.merge(report_texts, left_on='PtSSN', right_on='PatientSSN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     15288\n",
       "1      3627\n",
       "2      8009\n",
       "3     18068\n",
       "4      7227\n",
       "      ...  \n",
       "63     3921\n",
       "64    39853\n",
       "65     1191\n",
       "66    10167\n",
       "67    19351\n",
       "Name: ReportText, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['ReportText'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from medspacy.visualization import visualize_ent\n",
    "visualize_ent(nlp(df_combined['ReportText'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n",
      "Processing a report text\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "# spacy NER can only handle 1 million characters, so we'll take the last million for long texts\n",
    "# texts['ReportText'] = texts['ReportText'].map(lambda t: t[-1_000_000:])\n",
    "for text in df_combined['ReportText']:\n",
    "    print('Processing a report text')\n",
    "    doc = nlp(text)\n",
    "    ls.append({**{k+\"+\": v[0] for k,v in doc._.signs.items()}, **{k+\"-\": v[1] for k,v in doc._.signs.items()}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_signs = pd.DataFrame(ls)\n",
    "df_signs = df_signs.fillna(0).astype(int)\n",
    "# df_signs.to_csv('ner7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_signs['PtSSN'] = df_combined['PtSSN']\n",
    "df_signs = df_signs.set_index('PtSSN')\n",
    "df_signs.to_csv('ner8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\AppData\\Roaming\\Miniconda3\\envs\\ahrq\\lib\\site-packages\\ipykernel\\ipkernel.py:281: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_signs = df_signs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signs = pd.read_csv('ner8.csv').drop('PatientSSN', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signs['HEADACHE+'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-07d057b3da00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_signs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MOD'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_combined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DxErrorERCoded'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MOD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_combined' is not defined"
     ]
    }
   ],
   "source": [
    "df_signs['MOD'] = df_combined['DxErrorERCoded'] == 'MOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signs.loc[:,'VISION_CHANGES-':'NUCHAL_RIGIDITY-'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_signs.loc[:,'VISION_CHANGES-':'NUCHAL_RIGIDITY-'].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# text_train, text_test, lab_train, lab_test = train_test_split(texts['ReportText2'], texts['MOD'])\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=LogisticRegression(),\n",
    "    step=1,\n",
    "    cv=ShuffleSplit(10, test_size=0.25),\n",
    "    scoring=metrics.make_scorer(metrics.auc),\n",
    "    n_jobs=2,\n",
    ")\n",
    "rfecv.fit(df_signs.loc[:,:'NUCHAL_RIGIDITY-'], df_signs['MOD'])\n",
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signs.columns[np.where(rfecv.ranking_ == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_signs['ATAXIA+'], df_signs['MOD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_signs['NUCHAL_RIGIDITY+'], df_signs['ATAXIA+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "reducer = umap.UMAP()\n",
    "# embed = reducer.fit_transform(df_signs.loc[:,df_signs.columns[np.where(rfecv.ranking_ == 1)]])\n",
    "embed = reducer.fit_transform(df_signs.loc[:,:'NUCHAL_RIGIDITY-'])\n",
    "plt.scatter(embed[:,0], embed[:,1], c=np.where(df_signs['MOD'], 'red', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_signs[col] > 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "good_vars = []\n",
    "for col in df_signs.columns[:-1]:\n",
    "    print(col)\n",
    "    if (df_signs[col] > 0).any() and (df_signs[col] == 0).any():\n",
    "        t, p = fisher_exact(pd.crosstab(df_signs[col] > 0, df_signs['MOD']))\n",
    "        print(t, p)\n",
    "        if p < 0.2:\n",
    "            good_vars.append(col)\n",
    "    else:\n",
    "        print('skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, roc_curve\n",
    "\n",
    "kf = ShuffleSplit(n_splits=100, test_size=0.25)\n",
    "\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "log_probs = []\n",
    "fpr = []\n",
    "tpr = []\n",
    "for train_indices, test_indices in kf.split(df_signs):\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(df_signs.loc[train_indices,good_vars], df_signs['MOD'][train_indices])\n",
    "    x_test = df_signs.loc[test_indices,good_vars]\n",
    "    y_test = df_signs['MOD'][test_indices]\n",
    "    y_pred = clf.predict(x_test)\n",
    "    log_probs.append(clf.feature_log_prob_)\n",
    "#     acc = accuracy_score(df_signs['MOD'][test_indices], y_pred)\n",
    "#     f1s.append(f1_score(df_signs['MOD'][test_indices], y_pred))\n",
    "#     precs.append(precision_score(df_signs['MOD'][test_indices], y_pred))\n",
    "#     recs.append(recall_score(df_signs['MOD'][test_indices], y_pred))\n",
    "#     accs.append(acc)\n",
    "    roc = roc_curve(df_signs['MOD'][test_indices], \n",
    "                    clf.predict_proba(df_signs.loc[test_indices,good_vars])[:,1],\n",
    "                    drop_intermediate=False)\n",
    "    fpr.append(roc[0])\n",
    "    tpr.append(roc[1])\n",
    "print(f\"{np.mean(accs)} +/- {np.std(accs)}\")\n",
    "print(f\"{np.mean(f1s)} +/- {np.std(f1s)}\")\n",
    "print(f\"{np.mean(precs)} +/- {np.std(precs)}\")\n",
    "print(f\"{np.mean(recs)} +/- {np.std(recs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_interp = []\n",
    "fpr_interp = np.linspace(0,1,20)\n",
    "for f,t in zip(fpr, tpr):\n",
    "    tpr_interp.append(np.interp(fpr_interp, f, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.mean(tpr_interp, axis=0)\n",
    "s = np.std(tpr_interp, axis=0)\n",
    "plt.plot(fpr_interp, y)\n",
    "plt.fill_between(fpr_interp, y-s, y+s, alpha=0.2)\n",
    "plt.plot([0,1], [0,1], ls='--', c='tab:blue')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_log_prob = np.mean(np.array(log_probs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prob = np.exp(mean_log_prob)\n",
    "mean_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argpartition(np.abs(mean_prob[1] - mean_prob[0]), -10)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = mean_prob[1] - mean_prob[0]\n",
    "diff[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
